{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "Fixture\n",
      "Wood\n",
      "Facade\n",
      "Font\n",
      "Brickwork\n",
      "Building material\n",
      "Signage\n",
      "Door\n",
      "Commercial building\n",
      "Metal\n",
      "Texts:\n",
      "풀문스튜디오\n",
      "MARA\n",
      "풀문\n",
      "스튜디오\n",
      "MARA\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "# Set environment variable\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"ocr-project-386007-133b41eb4439.json\"\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import vision\n",
    "\n",
    "# Instantiates a client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# The name of the image file to annotate\n",
    "file_name = os.path.abspath('풀문스튜디오.jpg')\n",
    "\n",
    "# Loads the image into memory\n",
    "with io.open(file_name, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = vision.Image(content=content)\n",
    "\n",
    "# Performs label detection on the image file\n",
    "response = client.label_detection(image=image)\n",
    "labels = response.label_annotations\n",
    "\n",
    "print('Labels:')\n",
    "for label in labels:\n",
    "    print(label.description)\n",
    "    \n",
    "# Performs text detection on the image file\n",
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations\n",
    "\n",
    "print('Texts:')\n",
    "for text in texts:\n",
    "    print(text.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 검출하고 바운딩 박스 그린 이미지 저장\n",
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import vision_v1\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"ocr-project-386007-133b41eb4439.json\"\n",
    "\n",
    "client = vision_v1.ImageAnnotatorClient()\n",
    "img_path = '풀문스튜디오'\n",
    "with io.open(img_path+'.jpg', \"rb\") as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = vision_v1.types.Image(content=content)\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations[1:]\n",
    "\n",
    "im = Image.open(io.BytesIO(content))\n",
    "\n",
    "draw = ImageDraw.Draw(im)\n",
    "\n",
    "for text in texts:\n",
    "    vertices = [(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices]\n",
    "    draw.polygon(vertices, outline='red')\n",
    "\n",
    "im.save(f\"result_{img_path}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[description: \"풀문\"\n",
       " bounding_poly {\n",
       "   vertices {\n",
       "     x: 61\n",
       "     y: 80\n",
       "   }\n",
       "   vertices {\n",
       "     x: 183\n",
       "     y: 81\n",
       "   }\n",
       "   vertices {\n",
       "     x: 183\n",
       "     y: 135\n",
       "   }\n",
       "   vertices {\n",
       "     x: 61\n",
       "     y: 134\n",
       "   }\n",
       " },\n",
       " description: \"스튜디오\"\n",
       " bounding_poly {\n",
       "   vertices {\n",
       "     x: 188\n",
       "     y: 80\n",
       "   }\n",
       "   vertices {\n",
       "     x: 435\n",
       "     y: 81\n",
       "   }\n",
       "   vertices {\n",
       "     x: 435\n",
       "     y: 136\n",
       "   }\n",
       "   vertices {\n",
       "     x: 188\n",
       "     y: 135\n",
       "   }\n",
       " },\n",
       " description: \"MARA\"\n",
       " bounding_poly {\n",
       "   vertices {\n",
       "     x: 388\n",
       "     y: 442\n",
       "   }\n",
       "   vertices {\n",
       "     x: 410\n",
       "     y: 442\n",
       "   }\n",
       "   vertices {\n",
       "     x: 410\n",
       "     y: 448\n",
       "   }\n",
       "   vertices {\n",
       "     x: 388\n",
       "     y: 448\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바운딩 박스로 검출된 부분 crop 해서 저장\n",
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import vision_v1\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"ocr-project-386007-133b41eb4439.json\"\n",
    "\n",
    "client = vision_v1.ImageAnnotatorClient()\n",
    "img_path = '풀문스튜디오'\n",
    "\n",
    "with io.open(img_path+\".jpg\", \"rb\") as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = vision_v1.types.Image(content=content)\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations[1:]\n",
    "\n",
    "im = Image.open(io.BytesIO(content))\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    vertices = [(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices]\n",
    "    left = min(vertices, key=lambda x: x[0])[0]\n",
    "    upper = min(vertices, key=lambda x: x[1])[1]\n",
    "    right = max(vertices, key=lambda x: x[0])[0]\n",
    "    lower = max(vertices, key=lambda x: x[1])[1]\n",
    "    im_crop = im.crop((left, upper, right, lower))\n",
    "    im_crop.save(f\"result_{img_path}_{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바운딩 박스 부분 crop하고 글자는 검정 배경은 흰색으로 바꾸기(잘안됨)\n",
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import vision_v1\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"ocr-project-386007-133b41eb4439.json\"\n",
    "\n",
    "client = vision_v1.ImageAnnotatorClient()\n",
    "\n",
    "with io.open(\"풀문스튜디오.jpg\", \"rb\") as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = vision_v1.types.Image(content=content)\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations[1:]\n",
    "\n",
    "im = Image.open(io.BytesIO(content))\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    vertices = [(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices]\n",
    "    vertices.sort(key=lambda x: x[0])\n",
    "    left = vertices[0][0]\n",
    "    right = vertices[-1][0]\n",
    "    vertices.sort(key=lambda x: x[1])\n",
    "    top = vertices[0][1]\n",
    "    bottom = vertices[-1][1]\n",
    "\n",
    "    # crop the bounding box area\n",
    "    im_crop = im.crop((left, top, right, bottom))\n",
    "\n",
    "    # get character region\n",
    "    im_gray = im_crop\n",
    "    im_bin = im_gray.point(lambda x: 0 if x > 128 else 255)\n",
    "    region = im_bin.crop(im_bin.getbbox())\n",
    "\n",
    "    # save character region\n",
    "    region.save(f\"result_{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image_path = r'studio.jpg'\n",
    "\n",
    "# 이미지 로드\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# 그레이 스케일로 변환\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 이진화\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# 경계선 검출\n",
    "edges = cv2.Canny(thresh, 100, 200)\n",
    "\n",
    "# 결과 출력\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Inverted Image', thresh)\n",
    "cv2.imshow('Detected Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 750, 3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('cafe.jpg')\n",
    "img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
